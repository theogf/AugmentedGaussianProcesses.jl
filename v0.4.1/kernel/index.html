<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Kernels · AugmentedGaussianProcesses.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>AugmentedGaussianProcesses.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Home</a></li><li><a class="toctext" href="../background/">Background</a></li><li><a class="toctext" href="../userguide/">User Guide</a></li><li class="current"><a class="toctext" href>Kernels</a><ul class="internal"><li><a class="toctext" href="#Kernels-available-1">Kernels available</a></li><li><a class="toctext" href="#Hyperparameter-optimization-1">Hyperparameter optimization</a></li><li><a class="toctext" href="#!!!-In-construction-!!!-1">!!! In construction !!!</a></li></ul></li><li><a class="toctext" href="../examples/">Examples</a></li><li><a class="toctext" href="../comparison/">Julia GP Packages</a></li><li><a class="toctext" href="../api/">API</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Kernels</a></li></ul><a class="edit-page" href="https://github.com/theogf/AugmentedGaussianProcesses.jl/blob/master/docs/src/kernel.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Kernels</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Kernels-(Covariance-functions)-1" href="#Kernels-(Covariance-functions)-1">Kernels (Covariance functions)</a></h1><p>The <strong>kernel function</strong> or <strong>covariance function</strong> is a crucial part of Gaussian Processes. It determines the covariance matrices between set of points, and its behaviour and parameters determines almost completely a GP behaviour.</p><h2><a class="nav-anchor" id="Kernels-available-1" href="#Kernels-available-1">Kernels available</a></h2><p>To get a short introduction of some covariance functions available one can look at these <a href="http://mlg.eng.cam.ac.uk/teaching/4f13/1819/covariance%20functions.pdf">Slides from Rasmussen</a></p><p>We define <span>$\theta_i$</span> as the lengthscale (in case of <code>IsoKernel</code> <span>$\theta_i=\theta\;\forall i$</span>) and <span>$\sigma$</span> is the variance In this package covariance functions are progressively added for now the available kernels are :</p><ul><li>RBF Kernel or Squared Exponential Kernel</li></ul><div>\[k(x,x&#39;) = \sigma \exp\left(-\frac{1}{2}\sum_{i=1}^D\frac{(x_i-x_i&#39;)^2}{\theta_i^2}\right)\]</div><ul><li>Matern 3/2 Kernel</li></ul><div>\[k(x,x&#39;)= \sigma\left(1+\sqrt{3\sum \frac{(x_i - x_i&#39;)^2}{\theta_i^2}}\right)\exp\left(-\sqrt{3\sum \frac{(x_i - x_i&#39;)^2}{\theta_i^2}}\right)\]</div><p>More are coming, check the <a href="https://github.com/theogf/AugmentedGaussianProcesses.jl/projects/1">github projects</a> for updates .</p><h2><a class="nav-anchor" id="Hyperparameter-optimization-1" href="#Hyperparameter-optimization-1">Hyperparameter optimization</a></h2><p>The advantage of Gaussian Processes is that it is possible to optimize all the hyperparameters of the model by optimizing the lower bound on the loglikelihood. One can compute the gradient of it and apply a classical gradient descent algorithm.</p><p>Unlike most other packages, the derivatives are all computed analytically. Since the hyperparameters intervene in gradients one needs to compute the matrix derivatives via the kernel derivatives. If <span>$K$</span> was defined via <span>$k(x,x&#39;)$</span> then :</p><p>$ \frac{d K}{d\theta}  = J_\theta$</p><p>Where <span>$J_\theta$</span> was defined via <span>$\frac{dk(x,x&#39;)}{d\theta}$</span>, the rest of the work is simply matrix algebra.</p><h2><a class="nav-anchor" id="!!!-In-construction-!!!-1" href="#!!!-In-construction-!!!-1">!!! In construction !!!</a></h2><footer><hr/><a class="previous" href="../userguide/"><span class="direction">Previous</span><span class="title">User Guide</span></a><a class="next" href="../examples/"><span class="direction">Next</span><span class="title">Examples</span></a></footer></article></body></html>
