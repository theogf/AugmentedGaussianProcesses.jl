"""
Gaussian likelihood : ``p(y|f) = (y|f,系) ``
"""
struct GaussianLikelihood{T<:Real} <: Likelihood{T}
    系::AbstractVector{T}
    function GaussianLikelihood{T}(系::Real) where {T<:Real}
        new{T}([系])
    end
    function GaussianLikelihood{T}(系::AbstractVector) where {T<:Real}
        new{T}(系)
    end
end

function GaussianLikelihood(系::T=1e-3) where {T<:Real}
    GaussianLikelihood{T}(系)
end

function GaussianLikelihood(系::AbstractVector{T}) where {T<:Real}
    GaussianLikelihood{T}(系)
end

function pdf(l::GaussianLikelihood,y::Real,f::Real)
    pdf(Normal(y,l.系[1]),f)
end

function logpdf(l::GaussianLikelihood,y::Real,f::Real)
    logpdf(Normal(y,l.系[1]),f)
end

function init_likelihood(likelihood::GaussianLikelihood{T},nLatent::Integer,nSamples::Integer) where {T<:Real}
    if length(likelihood.系) ==1 && length(likelihood.系) != nLatent
        return GaussianLikelihood{T}([likelihood.系[1] for _ in 1:nLatent])
    elseif length(likelihood.系) != nLatent
        @warn "Wrong dimension of 系 : $(length(likelihood.系)), using first value only"
        return GaussianLikelihood{T}([likelihood.系[1] for _ in 1:nLatent])
    else
        return likelihood
    end
end

""" Return the labels in a vector of vectors for multiple outputs"""
function treat_labels!(y::AbstractArray{T,N},likelihood::L) where {T,N,L<:GaussianLikelihood}
    @assert T<:Real "For regression target(s) should be real valued"
    @assert N <= 2 "Target should be a matrix or a vector"
    if N == 1
        return [y]
    else
        return [y[:,i] for i in 1:size(y,2)]
    end
end

function local_updates!(model::VGP{GaussianLikelihood{T}}) where T
end

function local_updates!(model::SVGP{GaussianLikelihood{T}}) where T
    model.likelihood.系 .= 1.0/model.inference.nSamplesUsed *
    norm.(getindex.(model.y,[model.inference.MBIndices]).*model.魏.*model.渭)
    + opt_trace.((model.魏'.*model.魏),model.危 + sum.(model.K) )
end

""" Return the gradient of the expectation for latent GP `index` """
function expec_渭(model::SVGP{<:GaussianLikelihood},index::Integer)
    return model.y[index][model.inference.MBIndices]./model.likelihood.系[index]
end

function expec_渭(model::SVGP{<:GaussianLikelihood})
    return getindex.(model.y,[model.inference.MBIndices]))./model.likelihood.系[index]
end

function expec_危(model::SVGP{<:GaussianLikelihood},index::Integer)
    return 0.5/model.likelihood.系[index]*ones(model.inference.nSamplesUsed)
end

function expec_危(model::SVGP{<:GaussianLikelihood})
    return [0.5/model.likelihood.系[i]*ones(model.inference.nSamplesUsed) for i in 1:model.nLatent]
end

function natural_gradient!(model::VGP{GaussianLikelihood{T}}) where T
end

function global_update!(model::VGP{GaussianLikelihood{T}}) where T
    if model.inference.nIter == 0
        model.渭 .= model.y
    end
end

### Special case where the ELBO is equal to the marginal likelihood
function ELBO(model::VGP{<:GaussianLikelihood})
    return -0.5*sum(dot.(model.y,inv.(model.Knn.+Diagonal.(model.likelihood.系)).*model.y)
            + logdet.(model.Knn.+Diagonal.(model.likelihood.系))
            .+ model.nFeature*log(2.0))
end

function ELBO(model::SVGP{<:GaussianLikelihood})
    return expecLogLikelihood(model) - GaussianKL(model)
end

function expecLogLikelihood(model::SVGP{GaussianLikelihood{T}}) where T
    return -0.5*(model.inference.nSamplesUsed*sum(log.(2.*model.likelihood.系)) +
                sum(broadcast(x->dot(x,x),getindex.(model.y,[model.inference.MBIndices]).-model.魏.*model.渭) .+
                sum.(model.K)+opt_trace.(model.魏.*model.危,model.魏))./model.likelihood.系)
end

function hyperparameter_gradient_function(model::VGP{<:GaussianLikelihood})
    model.危 = inv.(model.invKnn.+model.likelihood.系.*I)
    A = (model.危.*(model.碌.*transpose.(model.渭)).-[I]).*model.危
    if model.IndependentPriors
        return (function(Jnn,index)
                    return 0.5*opt_trace(Jnn,A[index])
                end,
                function(kernel,index)
                    return 0.5/getvariance(kernel)*opt_trace(model.Knn[index],A[index])
                end)
    else
        return (function(Jnn,index)
            return 0.5*sum(opt_trace.(Jnn.*transpose(A[i])) for i in 1:model.nLatent)
                end,
                function(kernel,index)
                    return 0.5/getvariance(kernel)*sum(sum(model.Knn[1].*transpose(A[i])) for i in 1:model.nLatent)
                end)
    end
end
