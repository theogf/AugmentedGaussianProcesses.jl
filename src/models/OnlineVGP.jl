""" Class for sparse variational Gaussian Processes """
mutable struct OnlineVGP{L<:Likelihood,I<:Inference,T<:Real,V<:AbstractVector{T}} <: SparseGP{L,I,T,V}
    X::Matrix{T} #Feature vectors
    y::LatentArray #Output (-1,1 for classification, real for regression, matrix for multiclass)
    nDim::Int64 # Number of covariates per data point
    nFeatures::Int64 # Number of features of the GP (equal to number of points)
    nLatent::Int64 # Number of latent GPs
    IndependentPriors::Bool # Use of separate priors for each latent GP
    nPrior::Int64 # Equal to 1 or nLatent given IndependentPriors
    kernel::LatentArray{Kernel{T}}
    likelihood::Likelihood{T}
    inference::Inference{T}
    Zalg::ZAlg
    Zupdated::Bool
    Î¼::LatentArray{V}
    Î£::LatentArray{Symmetric{T,Matrix{T}}}
    Î·â‚::LatentArray{V}
    Î·â‚‚::LatentArray{Symmetric{T,Matrix{T}}}
    Î¼â‚€::LatentArray{PriorMean{T}}
    Z::LatentArray{Matrix{T}}
    Kmm::LatentArray{Symmetric{T,Matrix{T}}}
    invKmm::LatentArray{Symmetric{T,Matrix{T}}}
    Knm::LatentArray{Matrix{T}}
    Îº::LatentArray{Matrix{T}}
    Îºold::LatentArray{Matrix{T}}
    KÌƒ::LatentArray{V}
    Zâ‚::LatentArray{Matrix{T}}
    Kab::LatentArray{Matrix{T}}
    Îºâ‚::LatentArray{Matrix{T}}
    KÌƒâ‚::LatentArray{Matrix{T}}
    invDâ‚::LatentArray{Symmetric{T,Matrix{T}}}
    prevÎ·â‚::LatentArray{V}
    prevð“›â‚::LatentArray{T}
    verbose::Int64
    Autotuning::Bool
    atfrequency::Int64
    Zoptimizer::Union{LatentArray{Optimizer},Nothing}
    Trained::Bool
end

"""Create a sparse variational Gaussian Process model
Argument list :

**Mandatory arguments**
 # - `X` : input features, should be a matrix NÃ—D where N is the number of observation and D the number of dimension
 # - `y` : input labels, can be either a vector of labels for multiclass and single output or a matrix for multi-outputs (note that only one likelihood can be applied)
 - `kernel` : covariance function, can be either a single kernel or a collection of kernels for multiclass and multi-outputs models
 - `likelihood` : likelihood of the model, currently implemented : Gaussian, Bernoulli (with logistic link), Multiclass (softmax or logistic-softmax) see [`Likelihood`](@ref)
 - `inference` : inference for the model, can be analytic, numerical or by sampling, check the model documentation to know what is available for your likelihood see [`Inference`](@ref)
 # - `nInducingPoints` : number of inducing points
 - `ZAlg` : Algorithm to add automatically inducing points, `CircleKMeans` by default, options are : `OfflineKMeans`, `StreamingKMeans`, `Webscale`
**Optional arguments**
 - `verbose` : How much does the model print (0:nothing, 1:very basic, 2:medium, 3:everything)
 - `Autotuning` : Flag for optimizing hyperparameters
 - `atfrequency` : Choose how many variational parameters iterations are between hyperparameters optimization
 - `IndependentPriors` : Flag for setting independent or shared parameters among latent GPs
 - `Zoptimizer` : Optimizer for the inducing points locations
 - `ArrayType` : Option for using different type of array for storage (allow for GPU usage)
"""
function OnlineVGP(#X::AbstractArray{T1},y::AbstractArray{T2},
            kernel::Kernel,
            likelihood::Likelihood{T1},inference::Inference,
            Zalg::ZAlg=CircleKMeans()#,Sequential::Bool=false
            ;verbose::Integer=0,Autotuning::Bool=true,atfrequency::Integer=1,
            mean::Union{<:Real,AbstractVector{<:Real},PriorMean}=ZeroMean(),
            IndependentPriors::Bool=true, Zoptimizer::Union{Any,Nothing}=Nothing(),ArrayType::UnionAll=Vector) where {T1<:Real,T2}

            @assert check_implementation(:OnlineVGP,likelihood,inference) "The $likelihood is not compatible or implemented with the $inference"
            nLatent = 1
            nPrior = IndependentPriors ? nLatent : 1
            kernel = [deepcopy(kernel) for _ in 1:nPrior];
            Zupdated = false;
            Î¼ = LatentArray{ArrayType{T1}}()
            Î£ = LatentArray{Symmetric{T1,Matrix{T1}}}()
            Î·â‚ = LatentArray{ArrayType{T1}}()
            Î·â‚‚ = LatentArray{Symmetric{T1,Matrix{T1}}}()
            Î¼â‚€ = []
            if typeof(mean) <: Real
                Î¼â‚€ = [ConstantMean(mean)]
            elseif typeof(mean) <: AbstractVector{<:Real}
                Î¼â‚€ = [EmpiricalMean(mean)]
            else
                Î¼â‚€ = [mean]
            end
            Z = LatentArray{Matrix{T1}}()
            if !isnothing(Zoptimizer)
                Zoptimizer = [deepcopy(Zoptimizer) for _ in 1:nPrior]
            end
            Kmm = LatentArray{Symmetric{T1,Matrix{T1}}}()
            invKmm = LatentArray{Symmetric{T1,Matrix{T1}}}()
            Knm = LatentArray{Matrix{T1}}()
            Îº = LatentArray{Matrix{T1}}()
            Îºold = LatentArray{Matrix{T1}}()
            KÌƒ = LatentArray{ArrayType{T1}}()
            Zâ‚ = LatentArray{Matrix{T1}}()
            Kab = LatentArray{Matrix{T1}}()
            Îºâ‚ = LatentArray{Matrix{T1}}()
            KÌƒâ‚ = LatentArray{Matrix{T1}}()
            invDâ‚ = LatentArray{Symmetric{T1,Matrix{T1}}}()
            prevÎ·â‚ = LatentArray{ArrayType{T1}}()
            ð“›â‚ = LatentArray{T1}()
            inference.nIter = 1
            return OnlineVGP{typeof(likelihood),typeof(inference),T1,ArrayType{T1}}(
                    Matrix{T1}(undef,1,1),LatentArray(),
                    # nSample, nDim, nFeatures,
                    -1,0,nLatent,
                    IndependentPriors,nPrior,
                    kernel,likelihood,inference,
                    Zalg,Zupdated,
                    # Sequential,dataparsed,lastindex,
                    Î¼,Î£,Î·â‚,Î·â‚‚,Î¼â‚€,
                    Z,Kmm,invKmm,Knm,Îº,Îºold,KÌƒ,
                    Zâ‚,Kab,Îºâ‚,KÌƒâ‚,invDâ‚,prevÎ·â‚,ð“›â‚,
                    verbose,Autotuning,atfrequency,Zoptimizer,false
                    )
            # model.verbose = verbose;
            # model.Autotuning = Autotuning;
            # model.atfrequency = atfrequency;
            # model.OptimizeInducingPoints = OptimizeInducingPoints
            # model.Trained=false
end

function Base.show(io::IO,model::OnlineVGP{<:Likelihood,<:Inference,T}) where T
    print(io,"Online Variational Gaussian Process with a $(model.likelihood) infered by $(model.inference) ")
end
