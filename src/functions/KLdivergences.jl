## KL Divergence between the GP Prior and the variational distribution
function GaussianKL(model::AbstractGPModel, state)
    return mapreduce(GaussianKL, +, model.f, Zviews(model), state.kernel_matrices)
end

function GaussianKL(gp::AbstractLatent, X::AbstractVector, k_mat)
    return GaussianKL(mean(gp), pr_mean(gp, X), cov(gp), k_mat.K)
end

## See https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Multivariate_normal_distributions ##
function GaussianKL(
    Î¼::AbstractVector,
    Î¼â‚€::AbstractVector,
    Î£::Symmetric{T,Matrix{T}},
    K::Cholesky{T,Matrix{T}},
) where {T<:Real}
    return (logdet(K) - logdet(Î£) + tr(K \ Î£) + invquad(K, Î¼ - Î¼â‚€) - length(Î¼)) / 2
end

function GaussianKL(
    Î¼::AbstractVector{T},
    Î¼â‚€::AbstractVector,
    Î£::Symmetric{T,Matrix{T}},
    K::AbstractMatrix{T},
) where {T<:Real}
    K
    return (logdet(K) - logdet(Î£) + tr(K \ Î£) + dot(Î¼ - Î¼â‚€, K \ (Î¼ - Î¼â‚€)) - length(Î¼)) / 2
end

extraKL(::AbstractGPModel{T}, ::Any) where {T} = zero(T)

"""
    extraKL(model::OnlineSVGP)

Extra KL term containing the divergence with the GP at time t and t+1
"""
function extraKL(model::OnlineSVGP{T}, state) where {T}
    return mapreduce(
        +, model.f, state.opt_state, state.kernel_matrices
    ) do gp, opt_state, kernel_mat
        prev_gp = opt_state.previous_gp
        Îºâ‚Î¼ = kernel_mat.Îºâ‚ * mean(gp)
        KLâ‚ = prev_gp.prevð“›â‚
        KLâ‚ +=
            -sum(
                trace_ABt.(
                    Ref(prev_gp.invDâ‚),
                    [kernel_mat.KÌƒâ‚, kernel_mat.Îºâ‚ * cov(gp) * transpose(kernel_mat.Îºâ‚)],
                ),
            ) / 2
        KLâ‚ += dot(prev_gp.prevÎ·â‚, Îºâ‚Î¼) - dot(Îºâ‚Î¼, prev_gp.invDâ‚ * Îºâ‚Î¼) / 2
        return KLâ‚
    end
end

InverseGammaKL(Î±, Î², Î±â‚š, Î²â‚š) = GammaKL(Î±, Î², Î±â‚š, Î²â‚š)
"""
    GammaKL(Î±, Î², Î±â‚š, Î²â‚š)

KL(q(Ï‰)||p(Ï‰)), where q(Ï‰) = Ga(Î±,Î²) and p(Ï‰) = Ga(Î±â‚š,Î²â‚š)
"""
function GammaKL(Î±, Î², Î±â‚š, Î²â‚š)
    return sum(
        (Î± - Î±â‚š) .* digamma(Î±) .- log.(gamma.(Î±)) .+ log.(gamma.(Î±â‚š)) .+
        Î±â‚š .* (log.(Î²) .- log.(Î²â‚š)) .+ Î± .* (Î²â‚š .- Î²) ./ Î²,
    )
end

"""
    PoissonKL(Î», Î»â‚€)

KL(q(Ï‰)||p(Ï‰)), where q(Ï‰) = Po(Ï‰|Î») and p(Ï‰) = Po(Ï‰|Î»â‚€)
"""
function PoissonKL(Î»::AbstractVector{T}, Î»â‚€::Real) where {T}
    return Î»â‚€ * length(Î») - (one(T) + log(Î»â‚€)) * sum(Î») + sum(xlogx, Î»)
end

"""
    PoissonKL(Î», Î»â‚€, Ïˆ)

KL(q(Ï‰)||p(Ï‰)), where q(Ï‰) = Po(Ï‰|Î») and p(Ï‰) = Po(Ï‰|Î»â‚€) with Ïˆ = E[log(Î»â‚€)]
"""
function PoissonKL(
    Î»::AbstractVector{<:Real}, Î»â‚€::AbstractVector{<:Real}, Ïˆ::AbstractVector{<:Real}
)
    # sum(Î»â‚€) - sum(Î») + sum(xlogx, Î») - dot(Î», Ïˆ)
    # sum(Î»â‚€) - sum(Î») + mapreduce(xlogx, +, Î») - dot(Î», Ïˆ)
    return sum(Î»â‚€) - sum(Î») + sum(xlogx.(Î»)) - dot(Î», Ïˆ)
end

"""
    PolyaGammaKL(b, c, Î¸)

KL(q(Ï‰)||p(Ï‰)), where q(Ï‰) = PG(b,c) and p(Ï‰) = PG(b,0). Î¸ = ð‘¬[Ï‰]
"""
function PolyaGammaKL(b, c, Î¸)
    return dot(b, logcosh.(c / 2)) - dot(abs2.(c), Î¸) / 2
end

"""
    GIGEntropy(a, b, p)
    
Entropy of GIG variables with parameters a,b and p and omitting the derivative d/dpK_p cf <https://en.wikipedia.org/wiki/Generalized_inverse_Gaussian_distribution#Entropy>
"""
function GIGEntropy(a, b, p)
    sqrt_ab = sqrt.(a .* b)
    return (sum(log, a) - sum(log, b)) / 2 +
           mapreduce((p, s) -> log(2 * besselk(p, s)), +, p, sqrt_ab) +
           sum(
               sqrt_ab ./ besselk.(p, sqrt_ab) .*
               (besselk.(p + 1, sqrt_ab) + besselk.(p - 1, sqrt_ab)),
           ) / 2
end
